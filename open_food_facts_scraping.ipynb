{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0f390a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager # sustituye al archivo\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By # By es para buscar por tag, clase, id...\n",
    "from fake_useragent import UserAgent\n",
    "from selenium.webdriver.support.ui import WebDriverWait   # es para esperar\n",
    "from selenium.webdriver.support import expected_conditions as EC  # condiciones esperadas...\n",
    "from selenium.webdriver import ActionChains as AC   # acciones encadenadas, rollo doble click\n",
    "from selenium.webdriver.common.keys import Keys  # manejar teclas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b151070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and configure the Chrome web driver\n",
    "PATH = ChromeDriverManager().install()\n",
    "\n",
    "# Initialize the Chrome web driver\n",
    "driver = webdriver.Chrome(PATH)\n",
    "\n",
    "url = 'https://es.openfoodfacts.org/?sort_by=popularity'\n",
    "# Now you can use the 'driver' object for web scraping\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "340076e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.75 Safari/537.36\n"
     ]
    }
   ],
   "source": [
    "opciones=Options()\n",
    "\n",
    "\n",
    "opciones.add_experimental_option('excludeSwitches', ['enable-automation'])\n",
    "opciones.add_experimental_option('useAutomationExtension', False)\n",
    "\n",
    "opciones.headless=True   # si True, no aparece la ventana (headless=no visible)\n",
    "\n",
    "opciones.add_argument('user-data-dir=cookies')    # mantiene las coockies\n",
    "\n",
    "\n",
    "opciones.add_argument('--incognito')              # incognito\n",
    "\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "usuario=UserAgent().random\n",
    "\n",
    "\n",
    "\n",
    "print(usuario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8046a73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = []\n",
    "\n",
    "for page_num in range(2, 300):\n",
    "    \n",
    "\n",
    "    parent_div = driver.find_element_by_css_selector('ul#products_match_all')\n",
    "\n",
    "    # Find all the <a> elements inside the parent <div>\n",
    "    links = parent_div.find_elements_by_tag_name('a')\n",
    "\n",
    "    # Extract the href attribute from each link\n",
    "    for link in links:\n",
    "        href = link.get_attribute('href')\n",
    "        list1.append(href)\n",
    "        \n",
    "    button = driver.find_element_by_css_selector(f'a[href=\"/{page_num}?sort_by=popularity\"]')\n",
    "\n",
    "    # Click the button\n",
    "    button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49dba865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29800"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ba9ed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for e in list1:\n",
    "    # Open the webpage\n",
    "\n",
    "       \n",
    "        \n",
    "        driver.get(e)  # Replace with the actual webpage URL\n",
    "\n",
    "       \n",
    "        try:\n",
    "            # Find the <h2> element with the specific class name\n",
    "            h2_element = driver.find_element_by_css_selector('h2.title-1')\n",
    "\n",
    "            # Extract the text content of the <h2> element\n",
    "            product_name = h2_element.text\n",
    "        \n",
    "        except NoSuchElementException:\n",
    "            product_name = 'unknown'\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            # Find the <span> element with the specific id for brands\n",
    "            span_brands = driver.find_element_by_id('field_brands_value')\n",
    "\n",
    "            # Find the <a> elements within the <span> element for brands\n",
    "            a_elements_brands = span_brands.find_elements_by_tag_name('a')\n",
    "\n",
    "            # Extract the text content of each <a> element for brands\n",
    "            brands = [a_brand.text for a_brand in a_elements_brands]\n",
    "        \n",
    "        except NoSuchElementException:\n",
    "            brands = 'unknown'\n",
    "\n",
    "        # Find the <span> element with the specific id for packaging\n",
    "        # span_packaging = driver.find_element_by_id('field_packaging_value')\n",
    "\n",
    "        # Find the <a> elements within the <span> element for packaging\n",
    "        # a_elements_packaging = span_packaging.find_elements_by_tag_name('a')\n",
    "\n",
    "        # Extract the text content of each <a> element for packaging\n",
    "        # packaging = [a_packaging.text for a_packaging in a_elements_packaging]\n",
    "\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            # Find the <a> element within the <a> element with href=\"#panel_nutriscore_content\"\n",
    "            nutri_a_element = driver.find_element_by_css_selector('a[href=\"#panel_nutriscore_content\"]')\n",
    "\n",
    "            # Extract the \"grade\" class attribute of the <a> element for Nutri-Score\n",
    "            nutri_score = nutri_a_element.get_attribute(\"class\").split()[1].replace(\"grade_\", \"\").upper()\n",
    "        \n",
    "        except NoSuchElementException:\n",
    "            nutri_score = 'unknown'\n",
    "       \n",
    "    \n",
    "    \n",
    "        try:\n",
    "            # Find the <a> element within the <a> element with href=\"#panel_nova_content\"\n",
    "            nova_a_element = driver.find_element_by_css_selector('a[href=\"#panel_nova_content\"]')\n",
    "\n",
    "            # Extract the text content of the <h4> element within the <a> element for NOVA 4\n",
    "            nova_4 = nova_a_element.find_element_by_tag_name('h4').text\n",
    "        \n",
    "        except NoSuchElementException:\n",
    "            nova_4 = 'unknown'\n",
    "\n",
    "            \n",
    "            \n",
    "        try:\n",
    "            \n",
    "            # Find the <span> element with the specific id for countries\n",
    "            span_countries = driver.find_element_by_id('field_countries_value')\n",
    "\n",
    "            # Find the <a> elements within the <span> element for countries\n",
    "            a_elements_countries = span_countries.find_elements_by_tag_name('a')\n",
    "\n",
    "            # Extract the text content of each <a> element for countries\n",
    "            countries = [a_country.text for a_country in a_elements_countries]\n",
    "        \n",
    "        except NoSuchElementException:\n",
    "            countries = 'unknown'\n",
    "\n",
    "            \n",
    "            \n",
    "        try:\n",
    "            #Find the <div> element with the specific id for additives content\n",
    "            div_additives_content = driver.find_element_by_id('panel_additives_content')\n",
    "\n",
    "            #Find all the <h4> elements within the <div> element for additives content\n",
    "            h4_elements_additives = div_additives_content.find_elements_by_tag_name('h4')\n",
    "\n",
    "            #Extract the additive information from the <h4> elements\n",
    "            additives = [h4_additive.text for h4_additive in h4_elements_additives]\n",
    "            \n",
    "        except NoSuchElementException:\n",
    "            additives = 'unknown'\n",
    "\n",
    "        \n",
    "        try:\n",
    "            # Find the <a> element with the specific id for Eco-Score\n",
    "            a_ecoscore = driver.find_element_by_css_selector('a[href=\"#panel_ecoscore\"]')\n",
    "\n",
    "            # Extract the Eco-Score information from the <a> element\n",
    "            eco_score = a_ecoscore.find_element_by_css_selector('h4.attr_title').text\n",
    "        \n",
    "        except NoSuchElementException:\n",
    "            eco_score = 'unknown'\n",
    "\n",
    "        # Create a table\n",
    "        current_data = {\n",
    "            'Product Name': product_name,\n",
    "            'Brands': ', '.join(brands),\n",
    "            #'Packaging': ', '.join(packaging),\n",
    "            'NOVA 4': nova_4,\n",
    "            'Nutri-Score': nutri_score,\n",
    "            'Countries': ', '.join(countries),\n",
    "            'Additives': ', '.join(additives),\n",
    "            'Eco-Score': eco_score\n",
    "\n",
    "        }\n",
    "\n",
    "        from bs4 import BeautifulSoup\n",
    "        \n",
    "        try:\n",
    "            # Extract the page source\n",
    "            page_source = driver.page_source\n",
    "\n",
    "            # Parse the HTML data\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "            # Find the <tbody> element within the table\n",
    "            tbody_element = soup.find('table', attrs={'aria-label': 'Información nutricional'}).find('tbody')\n",
    "\n",
    "            # Create a dictionary to store the extracted values\n",
    "            extracted_data = {}\n",
    "\n",
    "            # Find the rows with the desired keys\n",
    "            for row in tbody_element.find_all('tr'):\n",
    "                key_element = row.find('td').find('span')\n",
    "                key = key_element.text.strip()\n",
    "\n",
    "                # Check if the current row contains 'Energía', 'Grasas saturadas', or 'Azúcares'\n",
    "                if key == 'Energía' or key == 'Grasas saturadas' or key == 'Azúcares':\n",
    "                    value_element = row.find_all('td')[1].find('span')\n",
    "                    value = value_element.text.strip()\n",
    "                    extracted_data[key] = value\n",
    "\n",
    "            # Add the extracted values to the existing data dictionary\n",
    "            current_data['Energía'] = extracted_data['Energía']\n",
    "            current_data['Grasas saturadas'] = extracted_data['Grasas saturadas']\n",
    "            current_data['Azúcares'] = extracted_data['Azúcares']\n",
    "        \n",
    "        \n",
    "        except Exception as e:\n",
    "        # Handle the exception\n",
    "            pass\n",
    "        \n",
    "        data_list.append(current_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "447a2477",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bbc123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/Users/david/Desktop/IronHack/Projects/food_advisor/raw/n1_300.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a83da665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29800 entries, 0 to 29799\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Product Name      29800 non-null  object\n",
      " 1   Brands            29800 non-null  object\n",
      " 2   NOVA 4            29800 non-null  object\n",
      " 3   Nutri-Score       29800 non-null  object\n",
      " 4   Countries         29800 non-null  object\n",
      " 5   Additives         29800 non-null  object\n",
      " 6   Eco-Score         29800 non-null  object\n",
      " 7   Energía           27656 non-null  object\n",
      " 8   Grasas saturadas  27656 non-null  object\n",
      " 9   Azúcares          27656 non-null  object\n",
      "dtypes: object(10)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a1b23b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
